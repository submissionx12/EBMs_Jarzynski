{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "from Sampler import Sampler\n",
    "from CNNModel import CNNModel\n",
    "from LightningMNISTClassifier import LightningMNISTClassifier\n",
    "\n",
    "## Imports for plotting\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded\n",
    "DATASET_PATH = \"../data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"../Jarzynski_EBMs\"\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Transformations applied on each image => make them a tensor and normalize between -1 and 1\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))\n",
    "                               ])\n",
    "\n",
    "# Loading the training dataset and manufacture a dataset containing only three digits: 2,3,6\n",
    "train_set = MNIST(root=DATASET_PATH, train=True, transform=transform, download=True)\n",
    "\n",
    "indices_2 = (train_set.targets == 2) \n",
    "indices_2 = indices_2.nonzero()[:5600] # 5600 samples of 2\n",
    "\n",
    "\n",
    "indices_3 = (train_set.targets == 3)\n",
    "indices_3 = indices_3.nonzero()[:2800] # 2800 samples of 3\n",
    "\n",
    "indices_6 = (train_set.targets == 6)\n",
    "indices_6 = indices_6.nonzero()[:1400] # 1400 samples of 6\n",
    "\n",
    "indices = torch.cat((indices_2,indices_6,indices_3)).squeeze()\n",
    "\n",
    "train_set.data, train_set.targets = train_set.data[indices], train_set.targets[indices]\n",
    "\n",
    "# Loading the test set\n",
    "test_set = MNIST(root=DATASET_PATH, train=False, transform=transform, download=True)\n",
    "indices = (test_set.targets == 2) | (test_set.targets == 6) | (test_set.targets == 3)\n",
    "test_set.data, test_set.targets = test_set.data[indices], test_set.targets[indices]\n",
    "\n",
    "\n",
    "# We define a set of data loaders that we can use for various purposes later.\n",
    "\n",
    "train_loader = data.DataLoader(train_set, batch_size=128, shuffle=True,  drop_last=False,  num_workers=4, pin_memory=True)\n",
    "test_loader  = data.DataLoader(test_set,  batch_size=256, shuffle=False, drop_last=True,  num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DeepEnergyModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, img_shape, batch_size, alpha= 1e-2, lr=1e-4, steps= 30, step_size= 5e-5, num_batch = 6,\n",
    "                 noise_level = 1e-4, sample_size = 1024, sampler_batch = 256, resample_std = 1.5, **CNN_args):\n",
    "\n",
    "        \"\"\"\n",
    "        Pytorch Lightning class for the training and validation\n",
    "\n",
    "        Inputs:\n",
    "            img_shape: Shape of the images as tensors (default 1*28*28 for MNIST images)\n",
    "            batch_size - Batch size for drawing data from the training set\n",
    "            alpha - constant which controls the regularization term \n",
    "            lr - Initial learning rate for ADAM\n",
    "            steps - Number of ULA steps for every model parameter update\n",
    "            step_size - ULA step size \n",
    "            noise_level - Noise for ULA\n",
    "            sample_size - The total number of walkers\n",
    "            num_batch - The total number of mini-batches drawn \n",
    "                        and run ULA on in each iteration of parameter update\n",
    "            sampler_batch - number of walkers in each mini-batch\n",
    "            resample_std - critical standard deviation for adaptive resampling\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        pretrained_filename = \"MNIST_checkpoint.ckpt\" # load the pre-trained classifer\n",
    "        self.classifier = LightningMNISTClassifier.load_from_checkpoint(pretrained_filename)\n",
    "        self.classifier.eval()\n",
    "        self.cnn = CNNModel(**CNN_args)\n",
    "        self.sampler = Sampler(self.cnn, img_shape=img_shape,sample_size = self.hparams.sample_size)\n",
    "\n",
    "        # run Langevin dynamics on the walkers without updating their weights\n",
    "        # to make sure they are samples from the initial distribution ~ exp(-U_\\theta)\n",
    "        self.sampler.examples = self.sampler.pure_generate_samples(self.cnn,self.sampler.examples,\n",
    "                                                                   steps=20000, \n",
    "                                                                   step_size=self.hparams.step_size,\n",
    "                                                                   noise_level = self.hparams.noise_level)\n",
    "\n",
    "        self.langevin_steps = 0\n",
    "        \n",
    "\n",
    "        # obtain the images on the full manufactured training set for \n",
    "        # estimation of the cross entropy \n",
    "\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))\n",
    "                               ])\n",
    "\n",
    "        data_set = MNIST(root=DATASET_PATH, train=True, transform=transform, download=True)\n",
    "\n",
    "        indices_2 = (data_set.targets == 2) \n",
    "        indices_2 = indices_2.nonzero()[:5600] # 5600 samples of 2\n",
    "\n",
    "\n",
    "        indices_3 = (data_set.targets == 3)\n",
    "        indices_3 = indices_3.nonzero()[:2800] # 2800 samples of 3\n",
    "\n",
    "        indices_6 = (data_set.targets == 6)\n",
    "        indices_6 = indices_6.nonzero()[:1400] # 1400 samples of 6\n",
    "\n",
    "        indices = torch.cat((indices_2,indices_6,indices_3)).squeeze()\n",
    "\n",
    "        data_set.data, _ = data_set.data[indices], data_set.targets[indices]\n",
    "        \n",
    "        data_loader = data.DataLoader(data_set, batch_size=data_set.data.shape[0], shuffle=True,  drop_last=False,  num_workers=4, pin_memory=True)\n",
    "        \n",
    "        for batch_idx, samples in enumerate(data_loader):\n",
    "              self.data = samples[0].to(device)\n",
    "                \n",
    "        # Initialize the normalization constant and the cross-entropy estimate\n",
    "        with torch.no_grad():\n",
    "            self.sampler.ce = ((-self.cnn(self.sampler.examples)).exp().mean()).log() + self.cnn(self.data).mean()\n",
    "            self.sampler.normalization = (-self.cnn(self.sampler.examples)).exp().mean()\n",
    "            self.sampler.normal_0 = self.sampler.normalization.clone().detach()\n",
    "    \n",
    "    def forward(self, x): # CNN model\n",
    "        z = self.cnn(x)\n",
    "        return z\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        # Energy models can have issues with momentum as the loss surfaces changes with its parameters.\n",
    "        # Hence, we set it to 0 by default.\n",
    "\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.hparams.lr, betas=(0.0, 0.999))\n",
    "        \n",
    "        initial_lr = 1\n",
    "        min_lr = 0\n",
    "        n_iter = 500 # the learning rate arrives at min_lr in n_iter iterations\n",
    "        \n",
    "        lambda1 = lambda epoch: max((initial_lr - epoch*(initial_lr - min_lr)/n_iter),1e-10) # linear decay\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
    "        \n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        real_imgs, _ = batch\n",
    "        \n",
    "        # Obtain samples from the set of walkers\n",
    "        index = torch.multinomial(torch.ones((self.hparams.sample_size,)),self.hparams.sampler_batch,replacement = False).to(device)\n",
    "        fake_imgs = self.sampler.examples[index]\n",
    "        \n",
    "        self.langevin_steps = self.langevin_steps + self.hparams.steps\n",
    "        \n",
    "        real_imgs = torch.cat([real_imgs], dim=0).detach()\n",
    "        fake_imgs = torch.cat([fake_imgs], dim=0).detach()\n",
    "        \n",
    "        # Predict the energy for all images\n",
    "        real_out = self.cnn(torch.cat([real_imgs], dim=0))\n",
    "        fake_out = self.cnn(torch.cat([fake_imgs], dim=0))\n",
    "        \n",
    "        # Calculate losses\n",
    "\n",
    "        weights = self.sampler.weights[index].clone().detach()\n",
    "        \n",
    "        reg_loss = self.hparams.alpha * ((real_out ** 2).mean() + ((fake_out ** 2)*weights/weights.sum()).sum())\n",
    "        cdiv_loss = -(fake_out*weights/weights.sum()).sum() + real_out.mean()\n",
    "        \n",
    "        loss = cdiv_loss + reg_loss\n",
    "        \n",
    "        # track the gradients of the parameters\n",
    "\n",
    "        parameters = [p for p in self.cnn.parameters() if p.grad is not None and p.requires_grad]\n",
    "        if len(parameters) == 0:\n",
    "            total_norm = 0.0\n",
    "        else:\n",
    "            total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach()) for p in parameters]))\n",
    "        \n",
    "        \n",
    "        langevin_steps = self.sampler.langevin_steps\n",
    "        \n",
    "        # Do ULA and weight updates on the walkers\n",
    "        fake_imgs = self.sampler.sample_new_exmps(steps=self.hparams.steps, \n",
    "                                                  step_size=self.hparams.step_size,\n",
    "                                                  noise_level = self.hparams.noise_level,\n",
    "                                                  batch_size = self.hparams.sampler_batch,\n",
    "                                                  num_batch = self.hparams.num_batch)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.sampler.ce = self.sampler.normalization.log() + self.cnn(self.data).mean()\n",
    "            \n",
    "        if torch.std(self.sampler.weights/self.sampler.weights.mean()) > self.hparams.resample_std and self.current_epoch > 150:\n",
    "            self.sampler.resample_multinomial()\n",
    "            \n",
    "        \n",
    "        # Logging\n",
    "        self.log('loss', loss)\n",
    "        self.log('loss_regularization', reg_loss)\n",
    "        self.log('loss_contrastive_divergence', cdiv_loss)\n",
    "\n",
    "        self.log('energy_avg_real', real_out.mean())\n",
    "        self.log('energy_avg_fake', fake_out.mean())\n",
    "\n",
    "        self.log('largest_log_weight',self.sampler.log_weights.max() )\n",
    "        self.log('smallest_log_weight',self.sampler.log_weights.min() )\n",
    "        self.log('mean_log_weight',self.sampler.log_weights.mean() )\n",
    "\n",
    "        self.log('f_norm',total_norm)\n",
    "        self.log('langevin_steps',langevin_steps)\n",
    "        self.log('weight_std',torch.std(self.sampler.weights/self.sampler.weights.mean()))\n",
    "        \n",
    "        self.log('cross_entropy',self.sampler.ce)\n",
    "        self.log('normalization',self.sampler.normalization)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        # For validating, we calculate the relative weights of the modes\n",
    "        # by passing all the generated samples/walkers through a classification\n",
    "        # neural network\n",
    "        \n",
    "        pred = self.classifier.forward(self.sampler.examples.clone().detach()).data.max(1, keepdim=True)[1].squeeze().to(torch.int)\n",
    "        class_index_6 = pred == 1\n",
    "        class_index_2 = pred == 0\n",
    "        class_index_3 = pred == 2\n",
    "        \n",
    "        weight_all = self.sampler.weights.clone().detach().sum()\n",
    "        weight_2 = self.sampler.weights[class_index_2].clone().detach().sum()/weight_all\n",
    "        weight_6 = self.sampler.weights[class_index_6].clone().detach().sum()/weight_all\n",
    "        weight_3 = self.sampler.weights[class_index_3].clone().detach().sum()/weight_all\n",
    "        \n",
    "        self.log('weight_2',weight_2)\n",
    "        self.log('weight_6',weight_6)\n",
    "        self.log('weight_3',weight_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SamplerCallback(pl.Callback):\n",
    "    \n",
    "    def __init__(self, num_imgs=128, every_n_epochs=4):\n",
    "        super().__init__()\n",
    "        self.num_imgs = num_imgs             # Number of images to plot\n",
    "        self.every_n_epochs = every_n_epochs # Only save those images every N epochs (otherwise tensorboard gets quite large)\n",
    "        \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        if trainer.current_epoch % 20 == 0:\n",
    "            \n",
    "            print(trainer.current_epoch)\n",
    "            torch.set_grad_enabled(True)  # Tracking gradients for sampling necessary\n",
    "            exmp_imgs = pl_module.sampler.examples\n",
    "            indices = torch.randint(0,exmp_imgs.shape[0],size = (self.num_imgs,))\n",
    "            exmp_imgs = exmp_imgs[indices].clone().detach()\n",
    "\n",
    "            grid = torchvision.utils.make_grid(exmp_imgs, nrow=8, normalize=True, value_range=(-1,1))\n",
    "            trainer.logger.experiment.add_image(\"sampler\", grid, global_step=trainer.current_epoch)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(**kwargs):\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, \"MNIST\"),\n",
    "                         accelerator='gpu', devices=1,\n",
    "                         max_epochs=600,\n",
    "                         log_every_n_steps=50,\n",
    "                         gradient_clip_val=1,\n",
    "                         # profiler=\"simple\",\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"min\", monitor='cross_entropy'),\n",
    "                                    SamplerCallback(every_n_epochs=2),\n",
    "                                    LearningRateMonitor(\"epoch\")\n",
    "                                   ])\n",
    "\n",
    "    pl.seed_everything(42)\n",
    "    model = DeepEnergyModel(**kwargs)\n",
    "    trainer.fit(model, train_loader, test_loader)\n",
    "    model = DeepEnergyModel.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "    \n",
    "    # No testing as we are more interested in other properties\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(img_shape=(1,28,28), \n",
    "                    batch_size=train_loader.batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
